# common config
seed: 1
gpu: "4"
print_frequency: 2
n_threads: 4
experiment_id: "debug_timestamp"

# data conifg
has_label: true
is_debug: false

dataset: "SemanticKitti"
nclasses: 20 # 19+1(ignored)
data_root: "/path/to/semantic-kitti-fov/sequences"

base_channels: 32
img_backbone: "resnet34"
imagenet_pretrained: true

# checkpoint model
# path to the folder generated by Recoder during training 
pretrained_path: "/path/to/PMF/experiments/PMF-SemanticKitti/log_xxxxx" 
best_model: "best_IOU_model.pth"

### data augmentation config ---------------------
augmentation:
  # flip
  p_flipx: 0.
  p_flipy: 0.5

  # translation
  p_transx: 0.5
  trans_xmin: -5
  trans_xmax: 5
  p_transy: 0.5
  trans_ymin: -3
  trans_ymax: 3
  p_transz: 0.5
  trans_zmin: -1
  trans_zmax: 0.

  # rotation
  p_rot_roll: 0.5
  rot_rollmin: -5
  rot_rollmax: 5
  p_rot_pitch: 0.5
  rot_pitchmin: -5
  rot_pitchmax: 5
  p_rot_yaw: 0.5
  rot_yawmin: 5
  rot_yawmax: -5

  # img jitter
  img_jitter: [0.4, 0.4, 0.4]

sensor:
  name: "HDL64"
  type: "perception-aware"
  proj_h: 384
  proj_w: 1232
  proj_ht: 256 
  proj_wt: 1024 
  h_pad: 7
  w_pad: 3

  img_mean:
    - 12.12
    - 10.88
    - 0.23
    - -1.04
    - 0.21
  img_stds:
    - 12.32
    - 11.47
    - 6.91
    - 0.86
    - 0.16  
post:
  KNN:
    use: false # This parameter default is false
    params:
      knn: 5
      search: 5
      sigma: 1.0
      cutoff: 1.0
